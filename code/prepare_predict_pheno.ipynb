{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results, section 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essentials\n",
    "import os, sys, glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "# Stats\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import pingouin as pg\n",
    "\n",
    "# Plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['svg.fonttype'] = 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/Users/lindenmp/Dropbox/Work/ResProjects/neurodev_cs_predictive/code/func/')\n",
    "from proj_environment import set_proj_env\n",
    "sys.path.append('/Users/lindenmp/Dropbox/Work/git/pyfunc/')\n",
    "from func import get_fdr_p_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_str = 't1Exclude'\n",
    "extra_str = '' # '_vol_norm' '_noboxcox' '_consist'\n",
    "edge_weight = 'streamlineCount' # 'streamlineCount' 'fa' 'mean_streamlineLength' 'adc'\n",
    "parc_scale = 200\n",
    "parcel_names, parcel_loc, drop_parcels, num_parcels, yeo_idx, yeo_labels = set_proj_env(exclude_str = exclude_str,\n",
    "                                                                                        parc_scale = parc_scale,\n",
    "                                                                                       extra_str = extra_str, edge_weight = edge_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['NORMATIVEDIR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['vol', 'str', 'ac', 'mc']\n",
    "phenos = ['Overall_Psychopathology','Psychosis_Positive','Psychosis_NegativeDisorg','AnxiousMisery','Externalizing','Fear']\n",
    "# phenos = ['Overall_Psychopathology','Psychosis_Positive','Psychosis_NegativeDisorg','AnxiousMisery','Externalizing','Fear',\n",
    "#          'F1_Exec_Comp_Res_Accuracy', 'F2_Social_Cog_Accuracy', 'F3_Memory_Accuracy', 'F1_Complex_Reasoning_Efficiency',\n",
    "#           'F2_Memory.Efficiency', 'F3_Executive_Efficiency', 'F4_Social_Cognition_Efficiency']\n",
    "# phenos = ['F1_Exec_Comp_Res_Accuracy', 'F2_Social_Cog_Accuracy', 'F3_Memory_Accuracy', 'F1_Complex_Reasoning_Efficiency',\n",
    "#           'F2_Memory.Efficiency', 'F3_Executive_Efficiency', 'F4_Social_Cognition_Efficiency']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.environ['FIGDIR']): os.makedirs(os.environ['FIGDIR'])\n",
    "os.chdir(os.environ['FIGDIR'])\n",
    "sns.set(style='white', context = 'talk', font_scale = 1)\n",
    "cmap = sns.color_palette(\"pastel\", 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "df_train = pd.read_csv(os.path.join(os.environ['NORMATIVEDIR'], 'train.csv'))\n",
    "df_train.set_index(['bblid', 'scanid'], inplace = True); print(df_train.shape)\n",
    "\n",
    "# Test\n",
    "df_test = pd.read_csv(os.path.join(os.environ['NORMATIVEDIR'], 'test.csv'))\n",
    "df_test.set_index(['bblid', 'scanid'], inplace = True); print(df_test.shape)\n",
    "df_node_test = pd.read_csv(os.path.join(os.environ['NORMATIVEDIR'], 'resp_test.csv'))\n",
    "df_node_test.set_index(['bblid', 'scanid'], inplace = True); print(df_node_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.loadtxt(os.path.join(os.environ['NORMATIVEDIR'], 'Z.txt'), delimiter = ' ').transpose()\n",
    "df_z = pd.DataFrame(data = z, index = df_node_test.index, columns = df_node_test.columns); print(df_z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smse = np.loadtxt(os.path.join(os.environ['NORMATIVEDIR'], 'smse.txt'), delimiter = ' ').transpose()\n",
    "df_smse = pd.DataFrame(data = smse, index = df_node_test.columns)\n",
    "\n",
    "smse_thresh = 1\n",
    "region_filter = df_smse.iloc[:,0] < smse_thresh\n",
    "print(region_filter.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward model\n",
    "synth_cov_test = pd.read_csv(os.path.join(os.environ['NORMATIVEDIR'], 'forward/synth_cov_test.txt'),\n",
    "                             delim_whitespace = True, names=[primary_covariate, 'sex_adj'])\n",
    "\n",
    "yhat_forward = np.loadtxt(os.path.join(os.environ['NORMATIVEDIR'], 'forward/yhat.txt'), delimiter = ' ').transpose()\n",
    "df_yhat_forward = pd.DataFrame(data = yhat_forward, index = synth_cov_test.index, columns = df_node_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at each roi, the differences between first and last age point in the synthetic data\n",
    "# for each node/metric, a negative value means that the nm predicted an overall decrease in y with age (i.e, a negative function),\n",
    "# while a positive values means that the nm predicted an overall increase in y with age (i.e., a positive function)\n",
    "df_yhat_tmp1 = df_yhat_forward[synth_cov_test['sex_adj'] == 0].iloc[-1,:] - df_yhat_forward[synth_cov_test['sex_adj'] == 0].iloc[0,:]\n",
    "df_yhat_tmp2 = df_yhat_forward[synth_cov_test['sex_adj'] == 1].iloc[-1,:] - df_yhat_forward[synth_cov_test['sex_adj'] == 1].iloc[0,:]\n",
    "df_yhat_diff = pd.concat((df_yhat_tmp1, df_yhat_tmp2), axis = 1)\n",
    "\n",
    "x = df_yhat_tmp1 > 0\n",
    "y = df_yhat_tmp2 > 0\n",
    "print(np.sum(x == y))\n",
    "\n",
    "# boolean that designates which regions carry with positive predicted change.\n",
    "# nm_is_pos = df_yhat_diff[0] > 0\n",
    "nm_is_pos = np.logical_and(x,y)\n",
    "print(np.sum(nm_is_pos))\n",
    "\n",
    "# flipping the z-stats in these regions has the effect of standardising their interpration across the brain to be inline\n",
    "# with the negative predicted change statement above\n",
    "df_z.loc[:,nm_is_pos] = df_z.loc[:,nm_is_pos] * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_bool = df_train.loc[:,phenos].isna().any(axis = 1)\n",
    "df_train = df_train.loc[~my_bool,:]\n",
    "print('N:', df_train.shape[0])\n",
    "\n",
    "my_bool = df_test.loc[:,phenos].isna().any(axis = 1)\n",
    "df_test = df_test.loc[~my_bool,:]\n",
    "df_z = df_z.loc[~my_bool,:]\n",
    "\n",
    "print('N:', df_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots()\n",
    "f.set_figwidth(10)\n",
    "f.set_figheight(5)\n",
    "axes.set_title('Phenotypes')\n",
    "\n",
    "for i, pheno in enumerate(phenos):\n",
    "    sns.kdeplot(df_test.loc[:,pheno], ax = axes, label = pheno)\n",
    "    axes.set_ylabel('density')\n",
    "    axes.set_xlabel('score')\n",
    "    axes.legend(loc='lower center', bbox_to_anchor=(0.5, 1.1), ncol=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize phenotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pheno in phenos:\n",
    "#     df_test.loc[:,pheno] = sp.stats.yeojohnson(df_test.loc[:,pheno])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f, axes = plt.subplots()\n",
    "# f.set_figwidth(10)\n",
    "# f.set_figheight(5)\n",
    "# axes.set_title('Phenotypes')\n",
    "\n",
    "# for i, pheno in enumerate(phenos):\n",
    "#     sns.kdeplot(df_test.loc[:,pheno], ax = axes, label = pheno)\n",
    "#     axes.set_ylabel('density')\n",
    "#     axes.set_xlabel('score')\n",
    "#     axes.legend(loc='lower center', bbox_to_anchor=(0.5, 1.1), ncol=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regress age/sex out of psychopathology phenotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covs = [primary_covariate, 'sex_adj', 'mprage_antsCT_vol_TBV', 'dti64MeanRelRMS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pd.DataFrame(index = covs, columns = phenos)\n",
    "p = pd.DataFrame(index = covs, columns = phenos)\n",
    "\n",
    "for cov in covs:\n",
    "    for pheno in phenos:\n",
    "        r.loc[cov,pheno] = sp.stats.pearsonr(df_test.loc[:,cov], df_test.loc[:,pheno])[0]\n",
    "        p.loc[cov,pheno] = sp.stats.pearsonr(df_test.loc[:,cov], df_test.loc[:,pheno])[1]\n",
    "\n",
    "f, ax = plt.subplots(1)\n",
    "f.set_figwidth(10)\n",
    "f.set_figheight(5)\n",
    "\n",
    "p = get_fdr_p_df(p)\n",
    "\n",
    "sns.heatmap(r[p<.05].astype(float), annot = True, center = 0, ax = ax, square = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit nuisance regression on the train data\n",
    "df_nuis_train = df_train.loc[:,covs]\n",
    "df_nuis_train = sm.add_constant(df_nuis_train)\n",
    "mdl = sm.OLS(df_train.loc[:,phenos], df_nuis_train).fit()\n",
    "\n",
    "# use regression coefficients from training set to residualize DVs in test set\n",
    "df_nuis_test = df_test.loc[:,covs]\n",
    "df_nuis_test = sm.add_constant(df_nuis_test)\n",
    "y_pred = mdl.predict(df_nuis_test)\n",
    "y_pred.columns = phenos\n",
    "df_test.loc[:,phenos] = df_test.loc[:,phenos] - y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pd.DataFrame(index = covs, columns = phenos)\n",
    "p = pd.DataFrame(index = covs, columns = phenos)\n",
    "\n",
    "for cov in covs:\n",
    "    for pheno in phenos:\n",
    "        r.loc[cov,pheno] = sp.stats.pearsonr(df_test.loc[:,cov], df_test.loc[:,pheno])[0]\n",
    "        p.loc[cov,pheno] = sp.stats.pearsonr(df_test.loc[:,cov], df_test.loc[:,pheno])[1]\n",
    "\n",
    "f, ax = plt.subplots(1)\n",
    "f.set_figwidth(10)\n",
    "f.set_figheight(5)\n",
    "\n",
    "p = get_fdr_p_df(p)\n",
    "\n",
    "sns.heatmap(r[p<.05].astype(float), annot = True, center = 0, ax = ax, square = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots()\n",
    "f.set_figwidth(10)\n",
    "f.set_figheight(5)\n",
    "axes.set_title('Phenotypes')\n",
    "\n",
    "for i, pheno in enumerate(phenos):\n",
    "    sns.kdeplot(df_test.loc[:,pheno], ax = axes, label = pheno)\n",
    "    axes.set_ylabel('density')\n",
    "    axes.set_xlabel('score')\n",
    "    axes.legend(loc='lower center', bbox_to_anchor=(0.5, 1.1), ncol=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subdirectory for specific normative model -- labeled according to parcellation/resolution choices and covariates\n",
    "outdir = os.path.join(os.environ['NORMATIVEDIR'], 'predict_cog_signflip')\n",
    "print(outdir)\n",
    "if not os.path.exists(outdir): os.mkdir(outdir);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_str = '|'.join(metrics)\n",
    "my_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_z.loc[:,region_filter].filter(regex = my_str).to_csv(os.path.join(outdir, 'X.csv'))\n",
    "df_z.filter(regex = my_str).to_csv(os.path.join(outdir, 'X.csv'))\n",
    "df_test.loc[:,phenos].to_csv(os.path.join(outdir, 'y.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
